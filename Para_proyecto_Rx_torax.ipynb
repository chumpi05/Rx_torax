{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chumpi05/Rx_torax/blob/main/Para_proyecto_Rx_torax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "# Detectar dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "data_flag = 'chestmnist'\n",
        "# data_flag = 'chestmnist'\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)\n",
        "\n",
        "# define a simple CNN model\n",
        "# añadiendo 20 capas convolucionales a la definición de la red neuronal.\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)) # 14x14\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)) # 7x7\n",
        "\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)) # 3x3 or 4x4 depending on padding/stride, let's assume 3x3 for now for calculation\n",
        "\n",
        "        # Adding more layers to reach 20 convolutional layers\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer14 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer15 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer16 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer17 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer18 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer19 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer20 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)) # 1x1 or 2x2\n",
        "\n",
        "        # Dynamically calculate the input size for the first linear layer\n",
        "        def _get_conv_output_size(self):\n",
        "            x = torch.randn(1, in_channels, 28, 28) # Assuming input image size is 28x28\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "            x = self.layer4(x)\n",
        "            x = self.layer5(x)\n",
        "            x = self.layer6(x)\n",
        "            x = self.layer7(x)\n",
        "            x = self.layer8(x)\n",
        "            x = self.layer9(x)\n",
        "            x = self.layer10(x)\n",
        "            x = self.layer11(x)\n",
        "            x = self.layer12(x)\n",
        "            x = self.layer13(x)\n",
        "            x = self.layer14(x)\n",
        "            x = self.layer15(x)\n",
        "            x = self.layer16(x)\n",
        "            x = self.layer17(x)\n",
        "            x = self.layer18(x)\n",
        "            x = self.layer19(x)\n",
        "            x = self.layer20(x)\n",
        "            return x.view(x.size(0), -1).size(1)\n",
        "\n",
        "        fc_input_size = _get_conv_output_size(self)\n",
        "\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(fc_input_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.layer7(x)\n",
        "        x = self.layer8(x)\n",
        "        x = self.layer9(x)\n",
        "        x = self.layer10(x)\n",
        "        x = self.layer11(x)\n",
        "        x = self.layer12(x)\n",
        "        x = self.layer13(x)\n",
        "        x = self.layer14(x)\n",
        "        x = self.layer15(x)\n",
        "        x = self.layer16(x)\n",
        "        x = self.layer17(x)\n",
        "        x = self.layer18(x)\n",
        "        x = self.layer19(x)\n",
        "        x = self.layer20(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "model = Net(in_channels=n_channels, num_classes=n_classes)\n",
        "\n",
        "# Inicializar modelo y mover a GPU\n",
        "model = Net(in_channels=n_channels, num_classes=n_classes).to(device)\n",
        "\n",
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "# training\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    for step, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
        "        inputs = inputs.to(device)\n",
        "        # Reshape targets only for multi-label task and ensure float type\n",
        "        if task == \"multi-label, binary-class\":\n",
        "          targets = targets.to(device).float().view(-1, n_classes)\n",
        "        else:\n",
        "          targets = targets.to(device) # Keep original shape and type for multi-class\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            train_correct += ((outputs > 0.0).int() == targets.int()).sum().item()\n",
        "            train_total += targets.size(0) * targets.size(1)\n",
        "        else:\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += targets.size(0)\n",
        "            train_correct += predicted.eq(targets.to(device)).sum().item() # Ensure both tensors are on the same device\n",
        "\n",
        "    # save the model\n",
        "    torch.save(model.state_dict(), 'chestmnist_cnn.pth')\n",
        "\n",
        "    print('Epoch [{}/{}]'.format(epoch + 1, NUM_EPOCHS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJiS6ELdhOFG",
        "outputId": "e82a3530-d994-4aba-f568-4209c5d1ab72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.12/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.23.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.8.28)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Usando dispositivo: cuda\n",
            "Mon Sep 22 03:54:12 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0             31W /   70W |    1294MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Dataset ChestMNIST of size 28 (chestmnist)\n",
            "    Number of datapoints: 78468\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: multi-label, binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'atelectasis', '1': 'cardiomegaly', '2': 'effusion', '3': 'infiltration', '4': 'mass', '5': 'nodule', '6': 'pneumonia', '7': 'pneumothorax', '8': 'consolidation', '9': 'edema', '10': 'emphysema', '11': 'fibrosis', '12': 'pleural', '13': 'hernia'}\n",
            "    Number of samples: {'train': 78468, 'val': 11219, 'test': 22433}\n",
            "    Description: The ChestMNIST is based on the NIH-ChestXray14 dataset, a dataset comprising 112,120 frontal-view X-Ray images of 30,805 unique patients with the text-mined 14 disease labels, which could be formulized as a multi-label binary-class classification task. We use the official data split, and resize the source images of 1×1024×1024 into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset ChestMNIST of size 28 (chestmnist)\n",
            "    Number of datapoints: 22433\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: multi-label, binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'atelectasis', '1': 'cardiomegaly', '2': 'effusion', '3': 'infiltration', '4': 'mass', '5': 'nodule', '6': 'pneumonia', '7': 'pneumothorax', '8': 'consolidation', '9': 'edema', '10': 'emphysema', '11': 'fibrosis', '12': 'pleural', '13': 'hernia'}\n",
            "    Number of samples: {'train': 78468, 'val': 11219, 'test': 22433}\n",
            "    Description: The ChestMNIST is based on the NIH-ChestXray14 dataset, a dataset comprising 112,120 frontal-view X-Ray images of 30,805 unique patients with the text-mined 14 disease labels, which could be formulized as a multi-label binary-class classification task. We use the official data split, and resize the source images of 1×1024×1024 into 1×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 614/614 [00:42<00:00, 14.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 614/614 [00:41<00:00, 14.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 614/614 [00:41<00:00, 14.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/3]\n"
          ]
        }
      ]
    }
  ]
}