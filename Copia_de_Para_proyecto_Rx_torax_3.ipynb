{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chumpi05/Rx_torax/blob/main/Copia_de_Para_proyecto_Rx_torax_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f84f598",
        "outputId": "121a59f1-c8e6-42e1-8828-047bdc17135c"
      },
      "source": [
        "# %% [markdown]\n",
        "# Create a new file for the Streamlit application.\n",
        "# %% [code]\n",
        "# Create an empty file named app.py with necessary imports\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"import streamlit as st\\n\")\n",
        "    f.write(\"import torch\\n\")\n",
        "    f.write(\"import numpy as np\\n\")\n",
        "    f.write(\"from PIL import Image\\n\")\n",
        "    f.write(\"import torchvision.transforms as transforms\\n\")\n",
        "    f.write(\"import torch.nn as nn\\n\")\n",
        "\n",
        "print(\"app.py created successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa7af8d1",
        "outputId": "96f7cb29-881d-4d7a-df9f-ced274facf1b"
      },
      "source": [
        "# %% [markdown]\n",
        "# Write code in `app.py` to load the saved PyTorch model and the image preprocessing transform.\n",
        "# %% [code]\n",
        "with open('app.py', 'a') as f:\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Define the CNN model class\\n\")\n",
        "    f.write(\"class Net(nn.Module):\\n\")\n",
        "    f.write(\"    def __init__(self, in_channels, num_classes):\\n\")\n",
        "    f.write(\"        super(Net, self).__init__()\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer1 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(32),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer2 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(32, 32, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(32),\\n\")\n",
        "    f.write(\"            nn.ReLU(),\\n\")\n",
        "    f.write(\"            nn.MaxPool2d(kernel_size=2, stride=2))\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer3 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(32, 64, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(64),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer4 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(64, 64, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(64),\\n\")\n",
        "    f.write(\"            nn.ReLU(),\\n\")\n",
        "    f.write(\"            nn.MaxPool2d(kernel_size=2, stride=2))\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer5 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(64, 128, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(128),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer6 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(128, 128, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(128),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer7 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(128, 128, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(128),\\n\")\n",
        "    f.write(\"            nn.ReLU(),\\n\")\n",
        "    f.write(\"            nn.MaxPool2d(kernel_size=2, stride=2))\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer8 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(128, 256, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(256),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer9 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(256, 256, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(256),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer10 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(256, 256, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(256),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer11 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(256, 256, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(256),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer12 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(256, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer13 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer14 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer15 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer16 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer17 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer18 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer19 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU())\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.layer20 = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Conv2d(512, 512, kernel_size=3, padding=1),\\n\")\n",
        "    f.write(\"            nn.BatchNorm2d(512),\\n\")\n",
        "    f.write(\"            nn.ReLU(),\\n\")\n",
        "    f.write(\"            nn.MaxPool2d(kernel_size=2, stride=2))\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        def _get_conv_output_size(self):\\n\")\n",
        "    f.write(\"            x = torch.randn(1, in_channels, 28, 28)\\n\")\n",
        "    f.write(\"            x = self.layer1(x)\\n\")\n",
        "    f.write(\"            x = self.layer2(x)\\n\")\n",
        "    f.write(\"            x = self.layer3(x)\\n\")\n",
        "    f.write(\"            x = self.layer4(x)\\n\")\n",
        "    f.write(\"            x = self.layer5(x)\\n\")\n",
        "    f.write(\"            x = self.layer6(x)\\n\")\n",
        "    f.write(\"            x = self.layer7(x)\\n\")\n",
        "    f.write(\"            x = self.layer8(x)\\n\")\n",
        "    f.write(\"            x = self.layer9(x)\\n\")\n",
        "    f.write(\"            x = self.layer10(x)\\n\")\n",
        "    f.write(\"            x = self.layer11(x)\\n\")\n",
        "    f.write(\"            x = self.layer12(x)\\n\")\n",
        "    f.write(\"            x = self.layer13(x)\\n\")\n",
        "    f.write(\"            x = self.layer14(x)\\n\")\n",
        "    f.write(\"            x = self.layer15(x)\\n\")\n",
        "    f.write(\"            x = self.layer16(x)\\n\")\n",
        "    f.write(\"            x = self.layer17(x)\\n\")\n",
        "    f.write(\"            x = self.layer18(x)\\n\")\n",
        "    f.write(\"            x = self.layer19(x)\\n\")\n",
        "    f.write(\"            x = self.layer20(x)\\n\")\n",
        "    f.write(\"            return x.view(x.size(0), -1).size(1)\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        fc_input_size = _get_conv_output_size(self)\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        self.fc = nn.Sequential(\\n\")\n",
        "    f.write(\"            nn.Linear(fc_input_size, 1024),\\n\")\n",
        "    f.write(\"            nn.ReLU(),\\n\")\n",
        "    f.write(\"            nn.Linear(1024, 512),\\n\")\n",
        "    f.write(\"            nn.ReLU(),\\n\")\n",
        "    f.write(\"            nn.Linear(512, num_classes))\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        x = self.layer1(x)\\n\")\n",
        "    f.write(\"        x = self.layer2(x)\\n\")\n",
        "    f.write(\"        x = self.layer3(x)\\n\")\n",
        "    f.write(\"        x = self.layer4(x)\\n\")\n",
        "    f.write(\"        x = self.layer5(x)\\n\")\n",
        "    f.write(\"        x = self.layer6(x)\\n\")\n",
        "    f.write(\"        x = self.layer7(x)\\n\")\n",
        "    f.write(\"        x = self.layer8(x)\\n\")\n",
        "    f.write(\"        x = self.layer9(x)\\n\")\n",
        "    f.write(\"        x = self.layer10(x)\\n\")\n",
        "    f.write(\"        x = self.layer11(x)\\n\")\n",
        "    f.write(\"        x = self.layer12(x)\\n\")\n",
        "    f.write(\"        x = self.layer13(x)\\n\")\n",
        "    f.write(\"        x = self.layer14(x)\\n\")\n",
        "    f.write(\"        x = self.layer15(x)\\n\")\n",
        "    f.write(\"        x = self.layer16(x)\\n\")\n",
        "    f.write(\"        x = self.layer17(x)\\n\")\n",
        "    f.write(\"        x = self.layer18(x)\\n\")\n",
        "    f.write(\"        x = self.layer19(x)\\n\")\n",
        "    f.write(\"        x = self.layer20(x)\\n\")\n",
        "    f.write(\"        x = x.view(x.size(0), -1)\\n\")\n",
        "    f.write(\"        x = self.fc(x)\\n\")\n",
        "    f.write(\"        return x\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Instantiate the model and load the state dictionary\\n\")\n",
        "    f.write(\"model = Net(in_channels=1, num_classes=14)\\n\")\n",
        "    f.write(\"model.load_state_dict(torch.load('chestmnist_cnn.pth', map_location=torch.device('cpu')))\\n\")\n",
        "    f.write(\"model.eval()\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Define the image preprocessing transform\\n\")\n",
        "    f.write(\"data_transform = transforms.Compose([\\n\")\n",
        "    f.write(\"    transforms.ToTensor(),\\n\")\n",
        "    f.write(\"    transforms.Normalize(mean=[.5], std=[.5])\\n\")\n",
        "    f.write(\"])\\n\")\n",
        "\n",
        "print(\"Model definition, loading, and transform definition added to app.py.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model definition, loading, and transform definition added to app.py.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87e43f4",
        "outputId": "1e9fb6da-17b3-47af-a478-313bfa1fba34"
      },
      "source": [
        "with open('app.py', 'a') as f:\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Streamlit interface\\n\")\n",
        "    f.write(\"st.title('Rx torax IA')\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"uploaded_file = st.file_uploader('sube tu rx aquÃ­', type=['jpg', 'jpeg'])\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"predict_button = st.button('Predict')\\n\")\n",
        "\n",
        "print(\"Streamlit interface elements added to app.py.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit interface elements added to app.py.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dab511a",
        "outputId": "f9b9c3b2-6069-4851-e640-9f770fbab851"
      },
      "source": [
        "with open('app.py', 'a') as f:\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Define the prediction function\\n\")\n",
        "    f.write(\"def predict(image):\\n\")\n",
        "    f.write(\"    image = data_transform(image).unsqueeze(0)\\n\")\n",
        "    f.write(\"    with torch.no_grad():\\n\")\n",
        "    f.write(\"        outputs = model(image)\\n\")\n",
        "    f.write(\"    sigmoid_outputs = torch.sigmoid(outputs)\\n\")\n",
        "    f.write(\"    predictions = (sigmoid_outputs > 0.5).int().squeeze(0)\\n\")\n",
        "    f.write(\"    return predictions\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Define the label mapping\\n\")\n",
        "    f.write(\"labels = {\\n\")\n",
        "    f.write(\"    0: 'atelectasis', 1: 'cardiomegaly', 2: 'effusion', 3: 'infiltration',\\n\")\n",
        "    f.write(\"    4: 'mass', 5: 'nodule', 6: 'pneumonia', 7: 'pneumothorax',\\n\")\n",
        "    f.write(\"    8: 'consolidation', 9: 'edema', 10: 'emphysema', 11: 'fibrosis',\\n\")\n",
        "    f.write(\"    12: 'pleural', 13: 'hernia'\\n\")\n",
        "    f.write(\"}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"# Handle prediction on button click\\n\")\n",
        "    f.write(\"if uploaded_file is not None and predict_button:\\n\")\n",
        "    f.write(\"    image = Image.open(uploaded_file).convert('RGB') # Ensure image is in RGB format for transformation\\n\")\n",
        "    f.write(\"    predictions = predict(image)\\n\")\n",
        "    f.write(\"    st.write('Predicciones:')\\n\")\n",
        "    f.write(\"    predicted_labels = [labels[i] for i, pred in enumerate(predictions) if pred == 1]\\n\")\n",
        "    f.write(\"    if predicted_labels:\\n\")\n",
        "    f.write(\"        for label in predicted_labels:\\n\")\n",
        "    f.write(\"            st.write(f'- {label}')\\n\")\n",
        "    f.write(\"    else:\\n\")\n",
        "    f.write(\"        st.write('No specific conditions detected.')\\n\")\n",
        "\n",
        "print(\"Prediction function and result display logic added to app.py.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction function and result display logic added to app.py.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08d28cfa",
        "outputId": "b89a8d32-aebc-41ca-dc15-588e099f9228"
      },
      "source": [
        "# Create a new file named requirements.txt and write the required libraries\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write(\"streamlit\\n\")\n",
        "    f.write(\"torch\\n\")\n",
        "    f.write(\"torchvision\\n\")\n",
        "    f.write(\"Pillow\\n\")\n",
        "    f.write(\"numpy\\n\")\n",
        "    f.write(\"medmnist\\n\")\n",
        "\n",
        "print(\"requirements.txt created successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt created successfully.\n"
          ]
        }
      ]
    }
  ]
}